{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc064f8-a567-4f09-8d03-96e57f04aaf0",
   "metadata": {},
   "source": [
    "# SSP/VSA embeddings in MiniGrid\n",
    "There are wrappers and features extractors included in this package that are are for the MiniGrid environments specfically.\n",
    "\n",
    "\n",
    "In the grid world environments, each cell can contain, at most, one object, which is specified by its type, colour, and state. Possible object types include wall, door, key, ball, box, goal, and lava,\n",
    "with each object having attributes like colour (from a predefined set) and states (open, closed, locked) that are specific to certain object types.\n",
    "\n",
    "The agent has a limited $7\\times7$ field of view and cannot see through walls. The default observations are represented as a $7\\times7\\times3$ integer matrix, where each vector $(i,j,:)$ denotes the type, colour, and state of the object at position $(i,j)$ within the agent's field of view.  The agent can perform seven actions: turn left, turn right, move forward, pick up an object, drop an object, open a door or box, and complete a task (which is not applicable in the tasks considered here).\n",
    "\n",
    "## Wrappers\n",
    "- **SSPMiniGridPoseWrapper:** Represents the agent's pose within the environment as an SSP,\n",
    "\\begin{align}\n",
    "   \\phi_{\\text{pose}} = \\phi \\left ( \\left [x,y,\\theta \\right ] \\right ) \n",
    "\\end{align}\n",
    "where $x,y$ is the agent's global position in the grid and $\\theta \\in \\{0,1,2,3\\}$ is an integer indicating the direction the agent is facing. Although the state variables are discrete due to the finite number of possible agent positions and orientations, they are treated as continuous variables in this embedding.\n",
    "- **SSPMiniGridViewWrapper:**  Uses the algebra of HRRs to encode both the agent's field of view and its pose. The information encoded includes a representation of the agent's pose (global position and orientation), $\\phi([x,y,\\theta])$; a representation of the object the agent is carrying (bound with a semantic pointer, $\\mathtt{HAS}$), if the agent is carrying an object (in these environments the agent is limited to carrying a single object, so the sum over objects carried in in equations below is over at most a single object); and a bundled representation of objects in the agent's field of view and their location relative to the agent. There are two versions of this:\n",
    "    - **obj_encoding='allbound':** The complete state encoding is constructed via binding and bundling operations:\n",
    "\\begin{align}\n",
    "   \\Phi_{\\text{view}} = \\phi([x,y,\\theta]) + \\mathtt{HAS} \\, \\circledast &\\sum_{\\text{objects carried}}  \\mathtt{ITEM}_i \\circledast \\mathtt{COLOUR}_i \\circledast \\mathtt{STATE}_i  \\\\\n",
    "     + &\\sum_{\\text{objects in view}} \\Delta\\phi_i \\circledast \\mathtt{ITEM}_i \\circledast \\mathtt{COLOUR}_i \\circledast \\mathtt{STATE}_i. \n",
    "\\end{align}\n",
    "The vector, $\\mathtt{ITEM}$, indicates the 'type' of an object in view, and can take on values $\\mathtt{DOOR}$, $ \\mathtt{KEY}$, $ \\mathtt{BALL}$, $ \\mathtt{BOX}$, $ \\mathtt{GOAL}$, or $ \\mathtt{LAVA}$. The vector, $\\mathtt{COLOUR}$, indicates the colour of the associated object. The vector, $\\mathtt{STATE}$, indicates the 'state' of an object, and can take on values $\\mathtt{OPEN}$, $ \\mathtt{CLOSED}$, or $ \\mathtt{LOCKED}$ (objects with fixed states, such as lava or balls, are encoded as being in the `open' state). Finally, $\\Delta\\phi_i$, encodes an object-in-view's location relative to the agent.\n",
    "    - **obj_encoding='slotfiller':** The complete state encoding is constructed via binding and bundling operations in a slot-filler style:\n",
    "\\begin{align}\n",
    "    \\Phi_{\\text{slot-filler}} = \\phi([x,y,\\theta]) + \\mathtt{HAS} \\, \\circledast &\\sum_{\\text{objects carried}} \\left ( \\mathtt{ITEM} \\circledast \\mathtt{I}_i + \\mathtt{COLOUR} \\circledast \\mathtt{C}_i + \\mathtt{STATE} \\circledast \\mathtt{S}_i \\right )\\\\\n",
    "     + &\\sum_{\\text{objects in view}} \\Delta\\phi_i \\circledast \\left ( \\mathtt{ITEM} \\circledast \\mathtt{I}_{i} + \\mathtt{COLOUR} \\circledast \\mathtt{C}_i + \\mathtt{STATE} \\circledast \\mathtt{S}_i \\right ),   \n",
    "\\end{align}\n",
    "where $\\mathtt{ITEM}$, $\\mathtt{COLOUR}$, and $\\mathtt{STATE}$ are random vectors that represent **slots** -- they indicate the type of the vector they are bound with -- while $\\mathtt{I}_i$, $\\mathtt{C}_i$, and $\\mathtt{S}_i$ denote the actual **values** of item type, colour, and state. The main difference between $\\Phi_{\\text{slot-filler}}$ and the prior \\gls*{hrr} embedding, $\\Phi_{\\text{view}}$, is representational overlap.\n",
    "In $\\Phi_{\\text{view}}$,  objects differing in any attribute (\\eg an open blue door versus a closed blue door) are dissimilar, whereas in $\\Phi_{\\text{slot-filler}}$, objects sharing properties have greater similarity (e.g., the representation of an open blue door is more similar to a closed blue door or a blue key compared to a red box).\n",
    "    - **Local vs gloabl:** (view_type='local' or 'global') In local mode we use  $\\Delta\\phi_i$, object-in-view's location relative to the agent. While in global mode, we  $\\phi_i$ instead, an object-in-view's global location in the env\n",
    "- **SSPMiniGridMissionWrapper:** Added on to the above encoding is a representation of the mission string -- a part of the observation space in some MiniGrid and all BabyAI tasks.\n",
    "    - Examples of misssion statements: “go to the {color} door”, “pick up the {color} {type}”, “go to a/the {color} {type}” + “and go to a/the {color} {type}” + “, then go to a/the {color} {type}” + “and go to a/the {color} {type}”\n",
    "    - This class is a work-in-progress. Currently, regex is used to decompose the string, looking for particular command patterns (e.g., \"go to _\", \"fetch a _\", \"pick up a _\", \"open the _\", \"put the _ near the _\") as well as object and color names. The idea is to break up the mission statement into different simple subcommands that each involve a sngle object and binding a command type representations (e.g., $\\mathtt{GO\\_TO}$, $\\mathtt{PICK\\_UP}$, $\\mathtt{OPEN}$) to object color and type representations (those used in the view encoding). This class will likely change in future versions of this package.\n",
    "- **SSPMiniGridWrapper** An interface to selct one of the above. Takes input encode_pose (true/false),encode_view (true/false), encode_mission (true/false). Currently encode_mission=True with encode_view=False is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75cbf2d-45a6-43f7-bfd8-a2aa38b02e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicoledumont/Documents/github/vsa-gym-wrapper/vsagym/spaces/ssp_box.py:107: UserWarning: Box bound precision lowered by casting to float32\n",
      "  warnings.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: uint8\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: uint8\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/nicoledumont/Documents/github/vsa-gym-wrapper/vsagym/wrappers/minigrid_wrappers/minigrid_view_wrapper.py:206: RuntimeWarning: invalid value encountered in divide\n",
      "  vsa_output = vsa_output / np.linalg.norm(vsa_output)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import minigrid\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.dirname(os.getcwd()))\n",
    "os.chdir(\"..\")\n",
    "import vsagym\n",
    "from vsagym.wrappers import minigrid_wrappers\n",
    "\n",
    "\n",
    "env = gym.make('MiniGrid-Dynamic-Obstacles-5x5-v0')\n",
    "env = minigrid_wrappers.SSPMiniGridWrapper(env,shape_out=251,\n",
    "                encode_pose=False,encode_view=True,encode_mission=False)\n",
    "observation, _ = env.reset()\n",
    "for t in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated or t == 4:\n",
    "        observation, _ = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30585c4e-ce56-40f8-a322-184c113d4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MiniGrid-Empty-5x5-v0')\n",
    "env = minigrid_wrappers.SSPMiniGridPoseWrapper(env,\n",
    "                             shape_out=251,\n",
    "                             decoder_method='from-set')\n",
    "observation, _ = env.reset()\n",
    "for t in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated or t == 4:\n",
    "        observation, _ = env.reset()\n",
    "env.close()\n",
    "\n",
    "env = gym.make('MiniGrid-KeyCorridorS3R1-v0')\n",
    "env = minigrid_wrappers.SSPMiniGridViewWrapper(env,\n",
    "                                               obj_encoding='allbound',\n",
    "                                               view_type='local',\n",
    "                                               shape_out=251,\n",
    "                                               decoder_method='from-set')\n",
    "observation, _ = env.reset()\n",
    "for t in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated or t == 4:\n",
    "        observation, _ = env.reset()\n",
    "env.close()\n",
    "\n",
    "env = gym.make('MiniGrid-KeyCorridorS3R1-v0')#, render_mode='rgb_array')\n",
    "env = minigrid_wrappers.SSPMiniGridViewWrapper(env,\n",
    "                                               obj_encoding='allbound',\n",
    "                                               view_type='global',\n",
    "                                               shape_out=251,\n",
    "                                               decoder_method='from-set')\n",
    "observation, _ = env.reset()\n",
    "for t in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated or t == 4:\n",
    "        observation, _ = env.reset()\n",
    "env.close()\n",
    "\n",
    "env = gym.make('MiniGrid-KeyCorridorS3R1-v0')\n",
    "env = minigrid_wrappers.SSPMiniGridViewWrapper(env,\n",
    "                                               obj_encoding='slotfiller',\n",
    "                                               view_type='local',\n",
    "                                               shape_out=251,\n",
    "                                               decoder_method='from-set')\n",
    "observation, _ = env.reset()\n",
    "for t in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated or t == 4:\n",
    "        observation, _ = env.reset()\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c579874-834e-433a-9992-d6527c500570",
   "metadata": {},
   "source": [
    "## Learning SSP parameters\n",
    "We can use these wrappers in combination with feature extractor networks so that the SSP parameters cna be learned.\n",
    "\n",
    "To just encode the agent's pose with a learnable mapping, we can use the MiniGridPoseWrapper and the FlatWrapper (because sb3 won't work with a dict observation space):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a731ebc-984b-4fad-a5d7-7af690098386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: uint8\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: uint8\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/nicoledumont/miniconda3/envs/rlzoo/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.3     |\n",
      "|    ep_rew_mean     | 0.241    |\n",
      "| time/              |          |\n",
      "|    fps             | 3826     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1498359f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MiniGrid-Empty-5x5-v0')\n",
    "env = minigrid_wrappers.MiniGridPoseWrapper(env, shape_out=251) # this will just output the agent's pose (x,y,direction) as the observation['image']\n",
    "env = minigrid_wrappers.FlatWrapper(env) # changes from a dict observation space (minigrid default) to a basic flat vector space (Box); ignores the mission; need this for sb3\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(features_extractor_class=vsagym.networks.SSPFeaturesExtractor,\n",
    "                       features_extractor_kwargs={'features_dim': 251,\n",
    "                                                  'length_scale': [1.,1.,0.1],\n",
    "                                                  'input_dim': 3}),\n",
    ")\n",
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b737d-ec64-48e3-beeb-6d511950706a",
   "metadata": {},
   "source": [
    "If we want to use the local view or mission embedding, we'll need to use special feature extractor networks and 'prep' wrappers.\n",
    "\n",
    "Note that the prep wrappers use a dict observation spaces so the flat wrapper is still needed. This was done for compatibility with RL models that assume a MiniGrid-like observation space (e.g., https://github.com/lcswillems/rl-starter-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844c11e-9da7-4215-b02e-daf674520ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 0.135    |\n",
      "| time/              |          |\n",
      "|    fps             | 1204     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = gym.make('MiniGrid-KeyCorridorS3R1-v0')\n",
    "env = minigrid_wrappers.PrepMiniGridViewWrapper(env, shape_out=201)\n",
    "env = minigrid_wrappers.FlatWrapper(env)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(features_extractor_class=vsagym.networks.SSPMiniGridViewFeatures,\n",
    "                       features_extractor_kwargs={'features_dim': 251,\n",
    "                                                  'length_scale': [1.,1.,0.1],\n",
    "                                              'basis_type': 'hex'}),\n",
    ")\n",
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474eca13-09b4-461a-b71b-0639389f57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MiniGrid-KeyCorridorS3R1-v0')\n",
    "env = minigrid_wrappers.PrepMiniGridMissionWrapper(env, shape_out=201)\n",
    "env = minigrid_wrappers.FlatWrapper(env)\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(features_extractor_class=vsagym.networks.SSPMiniGridMissionFeatures,\n",
    "                       features_extractor_kwargs={'features_dim': 251,\n",
    "                                                  'length_scale': [1.,1.,0.1],\n",
    "                                                  'basis_type': 'hex'}),\n",
    ")\n",
    "model.learn(total_timesteps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
